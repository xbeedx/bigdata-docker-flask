import os
import openai
import redis
import numpy as np
import random
import nltk

from nltk.corpus import words
from dotenv import load_dotenv
from pymongo import MongoClient
from flask import Flask, request, jsonify, render_template, redirect, url_for

load_dotenv()

app = Flask(__name__)

# Configuration de MongoDB
mongo_client = MongoClient("mongodb://localhost:27017/")
mongo_db = mongo_client["gpt_chat"]  # Ceci est le nom de la base de données
mongo_collection = mongo_db["conversations"]  # Ceci est le nom de la collection

# Configuration de Redis
redis_client = redis.Redis(host='localhost', port=6379, db=0)

# Fonction pour calculer la similarité cosinus entre deux vecteurs
def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

# Fonction pour obtenir les embeddings d'un texte
def get_embedding(text):
    response = openai.Embedding.create(input=[text], engine="text-embedding-ada-002")
    return response["data"][0]["embedding"]

# Page d'accueil qui charge le chat
@app.route('/')
def index():
    return render_template('chat.html')

@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.get_json()
        user_message = data['message']
        
        last_question = redis_client.get('last_user_question').decode('utf-8') if redis_client.get('last_user_question') else None
        last_response = redis_client.get('last_bot_response').decode('utf-8') if redis_client.get('last_bot_response') else None

        # Je calcule les embeddings et la similarité cosinus si la dernière question existe
        if last_question:
            last_question_embedding = get_embedding(last_question)
            user_message_embedding = get_embedding(user_message)
            similarity = cosine_similarity(last_question_embedding, user_message_embedding)
            
            # Si la similarité est élevée, la question actuelle est probablement liée à la dernière question
            if similarity > 0.7:
                # Je modifie la requête pour continuer la conversation sur le même sujet
                # En ajoutant la dernière réponse du bot au contexte
                messages = [
                    {"role": "system", "content": "Your name is Turring GPT, an AI assistant."},
                    {"role": "user", "content": last_question},
                    {"role": "assistant", "content": last_response},
                    {"role": "user", "content": user_message}
                ]
            else:
                # Sinon, je commence une nouvelle conversation
                messages = [
                    {"role": "system", "content": "Your name is Turring GPT, an AI assistant."},
                    {"role": "user", "content": user_message}
                ]
        else:
            # S'il n'y a pas de dernière question, je commence une nouvelle conversation
            messages = [
                {"role": "system", "content": "Your name is Turring GPT, an AI assistant."},
                {"role": "user", "content": user_message}
            ]

        tools = [
        {
            "type": "function",
            "function": {
                "name": "game",
                "description": "Play a game",
                "parameters": {
                    "type": "object",
                    "properties": {},
                    "required": []
                },
            },
        }
        ]
        
        # Interaction avec l'API OpenAI
        openai.api_key = os.getenv('OPENAI_API_KEY')
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=messages,
            tools=tools,
        )
        bot_response = response['choices'][0]['message']['content']

        tool_calls = response['choices'][0]['message'].get('tool_calls')

        if tool_calls:
            available_functions = {
                "game": game,
            }

            function_to_call = available_functions[tool_calls[0].function.name]
            function_to_call()

            return jsonify({"redirect": tool_calls[0].function.name})
        
        # Je sauvegarde de la conversation dans MongoDB
        mongo_collection.insert_one({'user': user_message, 'bot': bot_response})
        
        # Je met en cache de la dernière question et réponse avec Redis
        redis_client.set('last_user_question', user_message)
        redis_client.set('last_bot_response', bot_response)
        
        return jsonify({'bot': bot_response})
    except Exception as e:
        print(e)
        return jsonify({'bot': "Erreur : impossible de recevoir une réponse."}), 500

@app.route('/game', methods=['GET'])
def game():
    global password 
    password = random.choice(words.words())
    global level
    level = 1
    global nbRequests
    nbRequests = 0
    return render_template('game.html')

@app.route('/gameGuess', methods=['POST'])
def gameGuess():
    data = request.get_json()
    user_guess = data['guess']
    return jsonify({'response':  user_guess == password, 'level':  level, 'nbRequests': nbRequests})

@app.route('/gameChat', methods=['POST'])
def gameChat():
    try:
        data = request.get_json()
        user_message = data['message']

        prompt = f"""
        The password is {password}
        """

        messages = [
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": user_message}
                ]

        openai.api_key = os.getenv('OPENAI_API_KEY')
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=messages,
        )
        bot_response = response['choices'][0]['message']['content']

        global nbRequests
        nbRequests+=1

        return jsonify({'bot': bot_response})
    except Exception as e:
        print(e)
        return jsonify({'bot': "Erreur : impossible de recevoir une réponse."}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', debug=True)